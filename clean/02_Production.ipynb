{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`untar_data` is a fast.ai function to download and decompress data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning not always good with Tabular data. Better for data with high cardinality e.g. Postcodes, Product IDs.\n",
    "\n",
    "Deep learning wasn't good at text generation by the time of this course -> bu transformers architecture have improved this over time.\n",
    "\n",
    "Deep learning is OK at captioning, but not always accurate.\n",
    "\n",
    "Lots you can do with deep learning *if* you think creatively about how one mode of data (e.g. language, text) can be used for other modes (e.g. names of proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Model to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Practice of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Your Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The State of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text (natural language processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining text and images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new version of fast.ai, you can use:\n",
    "\n",
    "`learn=tabular_learner(dls, metrics=accuracy)`\n",
    "\n",
    "`learn.fit_one_cycle(2)`\n",
    "\n",
    "Generally there won't be a model available for tabular data to do transfer learning. So you need to fit one cycle, rather than fine tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Drivetrain Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean\n",
    "To download images with Bing Image Search, sign up at [Microsoft Azure](https://azure.microsoft.com/en-us/services/cognitive-services/bing-web-search-api/) for a free account. You will be given a key, which you can copy and enter in a cell as follows (replacing 'XXX' with your key and executing it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('AZURE_SEARCH_KEY', 'XXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_images_bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_images_bing(key, 'grizzly bear')\n",
    "ims = results.attrgot('contentUrl')\n",
    "len(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "ims = ['http://3.bp.blogspot.com/-S1scRCkI3vY/UHzV2kucsPI/AAAAAAAAA-k/YQ5UzHEm9Ss/s1600/Grizzly%2BBear%2BWildlife.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = 'images/grizzly.jpg'\n",
    "download_url(ims[0], dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(dest)\n",
    "im.to_thumb(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_types = 'grizzly','black','teddy'\n",
    "path = Path('bears')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in bear_types:\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, f'{o} bear')\n",
    "        download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = get_image_files(path)\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = verify_images(fns)\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.map(Path.unlink);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebar: Getting Help in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Data to DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOST IMPORTANT data structure for the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = bears.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish))\n",
    "dls = bears.dataloaders(path)\n",
    "dls.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = bears.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeros'))\n",
    "dls = bears.dataloaders(path)\n",
    "dls.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\n",
    "dls = bears.dataloaders(path)\n",
    "dls.train.show_batch(max_n=4, nrows=1, unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\n",
    "dls = bears.dataloaders(path)\n",
    "dls.train.show_batch(max_n=8, nrows=2, unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your Model, and Using It to Clean Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = bears.new(\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms())\n",
    "dls = bears.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n",
    "# for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Your Model into an Online Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path()\n",
    "path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner(path/'export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf.predict('images/grizzly.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf.dls.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Notebook App from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "btn_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# For the book, we can't actually click an upload button, so we fake it\n",
    "btn_upload = SimpleNamespace(data = ['images/grizzly.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PILImage.create(btn_upload.data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pl = widgets.Output()\n",
    "out_pl.clear_output()\n",
    "with out_pl: display(img.to_thumb(128,128))\n",
    "out_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,pred_idx,probs = learn_inf.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_pred = widgets.Label()\n",
    "lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
    "lbl_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run = widgets.Button(description='Classify')\n",
    "btn_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(img.to_thumb(128,128))\n",
    "    pred,pred_idx,probs = learn_inf.predict(img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
    "\n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Putting back btn_upload to a widget for next cell\n",
    "btn_upload = widgets.FileUpload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VBox([widgets.Label('Select your bear!'), \n",
    "      btn_upload, btn_run, out_pl, lbl_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Your Notebook into a Real App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# !pip install voila\n",
    "# !jupyter serverextension enable --sys-prefix voila "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying your app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Avoid Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unforeseen Consequences and Feedback Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Writing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n",
    "1. Where do text models currently have a major deficiency?\n",
    "1. What are possible negative societal implications of text generation models?\n",
    "1. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n",
    "1. What kind of tabular data is deep learning particularly good at?\n",
    "1. What's a key downside of directly using a deep learning model for recommendation systems?\n",
    "1. What are the steps of the Drivetrain Approach?\n",
    "1. How do the steps of the Drivetrain Approach map to a recommendation system?\n",
    "1. Create an image recognition model using data you curate, and deploy it on the web.\n",
    "1. What is `DataLoaders`?\n",
    "1. What four things do we need to tell fastai to create `DataLoaders`?\n",
    "1. What does the `splitter` parameter to `DataBlock` do?\n",
    "1. How do we ensure a random split always gives the same validation set?\n",
    "1. What letters are often used to signify the independent and dependent variables?\n",
    "1. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?\n",
    "1. What is data augmentation? Why is it needed?\n",
    "1. What is the difference between `item_tfms` and `batch_tfms`?\n",
    "1. What is a confusion matrix?\n",
    "1. What does `export` save?\n",
    "1. What is it called when we use a model for getting predictions, instead of training?\n",
    "1. What are IPython widgets?\n",
    "1. When might you want to use CPU for deployment? When might GPU be better?\n",
    "1. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?\n",
    "1. What are three examples of problems that could occur when rolling out a bear warning system in practice?\n",
    "1. What is \"out-of-domain data\"?\n",
    "1. What is \"domain shift\"?\n",
    "1. What are the three steps in the deployment process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n",
    "\n",
    "> If the pictures of the bear you are trying to classify is facing away from the camera, and the images in the training data are only of bears front on.*\n",
    "\n",
    "2. Where do text models currently have a major deficiency?\n",
    "\n",
    "> Conversation. Better at classification or translation.\n",
    "\n",
    "3. What are possible negative societal implications of text generation models?\n",
    "\n",
    "> Toxic languge reproduced. Disinformation reproduced. Generated text relied on by humans, as if created by humans.\n",
    "\n",
    "4. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n",
    "\n",
    "> Augmenting the process, with human review.\n",
    "\n",
    "5. What kind of tabular data is deep learning particularly good at?\n",
    "\n",
    "> High cardinality variables - those which have lots and lots of discrete levels, i.e. postcodes or product codes.\n",
    "\n",
    "6. What's a key downside of directly using a deep learning model for recommendation systems?\n",
    "\n",
    "> Example of prediction <> recommendation issue: if I buy a book by one author, I'm probably already aware of that author and other titles. So showing other titles is not necessarily recommending something I might be interested in buying that I wouldn't have come to myself, it is predicting what I will buy next.\n",
    "\n",
    "7. What are the steps of the Drivetrain Approach?\n",
    "\n",
    "> See 'The Drivetrain Approach' - a process for building data products:\n",
    "* Firstly, Define objective - e.g. maximise 5 year profit\n",
    "* Secondly, Levers or inputs to control - e.g. price to set\n",
    "* Thirdly, What data can we collect - e.g. data which can tell you as you change you levers, how you impact your objective\n",
    "* Finally, How levers influence the objective - e.g. to determine how the levers influence the objective, we build models.\n",
    "\n",
    "8. How do the steps of the Drivetrain Approach map to a recommendation system?\n",
    "\n",
    "> Firstly, **objective** is to drive sales. Secondly, **levers** are rankings of products for recommendation to a user. Thirdly, **data** is generated from randomized experiments that test a wide range of recommendations for a wide range of customers. Then data is used on historic purchases by people similar the the user. Finally, produce **models** that predict the purchase probability for products based on whether the customers are shown the recommendation or not. \n",
    "\n",
    "9. **Create an image recognition model using data you curate, and deploy it on the web.**\n",
    "\n",
    "> NB: Use Binder -> A web service that converts the notebook documents in a specified repository into a web application. It creates sharable notebooks that can be accessed by anyone with a single click. It also runs the notebooks on its own virtual machine that stores all the files that are needed to run in the cloud.\n",
    "\n",
    "10. What is `DataLoaders`?\n",
    "\n",
    "> `Dataloaders` provides the data for your model. `Dataloaders` is a fastai class that stores multiple DataLoader objects you pass to it, normally a train and a valid.\n",
    "\n",
    "11. What four things do we need to tell fastai to create `DataLoaders`?\n",
    "\n",
    "> 1. The data we need -> independent and dependent variables\n",
    "> 2. How to get the list of items\n",
    "> 3. How to label these items\n",
    "> 4. How to create the validation set\n",
    "\n",
    "> Data Block: A class that stores all the preprocessing steps to prepare the dataset for the model. It sets the blocks parameter to two or more of the TransformBlock classes to specify the input and output data types. It sets the `get_items` parameter to a function to specify how to get the data. It sets the splitter parameter to a split function to specify how to split the training and validation sets. It sets the `get_y` parameter to a function to specify how to get the label values. It also returns the `DataBlock` object.\n",
    "\n",
    "> The DataBlocks class needs the blocks, get_items, splitter, and get_y parameters to be specified to create the DataLoaders object.\n",
    "\n",
    "12. What does the `splitter` parameter to `DataBlock` do?\n",
    "\n",
    "> `splitter` setermines how to split the data into train and validtion sets\n",
    "\n",
    "13. How do we ensure a random split always gives the same validation set?\n",
    "\n",
    "> Fix the random seed, using `seed = 42`\n",
    "\n",
    "14. What letters are often used to signify the independent and dependent variables?\n",
    "\n",
    "> The independent variable is often referred to as x and the dependent variable is often referred to as y.\n",
    "\n",
    "15. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?\n",
    "\n",
    "> Crop: A technique that saves a portion of the image that fits in a square shape of the specified image size. It helps improve the performance of the model by adding images to the training set where the object isn’t fully visible. It can also lose important details in the image that are cropped out.\n",
    "\n",
    "> Pad: A technique that resizes the image to the specified image size while preserving the aspect ratio. It helps create the square shape that the model expects by adding black pixels to the shortest sides of the image. It can also create blank spaces and lower the resolution of the useful part of the image.\n",
    "\n",
    "> Squish: A technique that squeezes or stretches the image to the specified image size without preserving the aspect ratio. It helps resize the image to the square shape that the model expects. It can also cause unrealistic proportions in the image that confuses the model and lowers the accuracy.\n",
    "\n",
    "> fast.ai suggest randomly cropping different areas of an image to help the model learn to focus on objects in different sizes and on different locations in the image. This approach can also help present the images in a way that reflects the real world where the same object is framed differently in different images.\n",
    "\n",
    "16. What is data augmentation? Why is it needed?\n",
    "\n",
    "> Data augmentation is a technique to create variations in the dataset by modifying versions of the images in the dataset. It can involve flipping, rotating, scaling, padding, cropping, moving, and resizing images.\n",
    "\n",
    "> Data augmentation provides new and different examples, that prepares a model for a greater range of possibilities in the real world.\n",
    "\n",
    "17. What is the difference between `item_tfms` and `batch_tfms`?\n",
    "\n",
    "> Item Transforms (`item_Tfms`): A parameter that applies the specified `Transform` functions to the images in the dataset before separating them into mini-batches. It also performs the transformations on the CPU.\n",
    "\n",
    "> Batch Transforms (`batch_Tfms`): A parameter that applies the specified `Transforms` functions to the mini-batches after resizing and separating them from the dataset. It also performs the transformations on the GPU.\n",
    "\n",
    "18. What is a confusion matrix?\n",
    "\n",
    "> A matrix that helps visualise the performance of a model, mapping True Positive, True Negative, False Positive, False Negative results.\n",
    "\n",
    "19. What does `export` save?\n",
    "\n",
    "> `export` saves a trained model so you can use the model to make predictions in production. `export` saves everything required to build the `Learner` object using the pickle protocol, which includes the architecture, weights, and biases, and definitions that specify how to create the DataLoaders object.\n",
    "\n",
    "20. What is it called when we use a model for getting predictions, instead of training?\n",
    "\n",
    "> Inference\n",
    "\n",
    "21. What are IPython widgets?\n",
    "\n",
    "> Interactive HTML widgets for Jupyter notebooks\n",
    "\n",
    "22. When might you want to use CPU for deployment? When might GPU be better?\n",
    "\n",
    "> CPU for price, when you only require inferences one at a time (i.e. not parallel processing). GPU when conducting multiple inferences at the same time. GPU can also be cost effective when enough volume to conduct inferences in btaches.\n",
    "\n",
    "23. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?\n",
    "\n",
    "> requires users to have an internet connection to use the model.\n",
    "> causes delays while the data transmitted to and from the server.\n",
    "> requires protecting the sensitive data that’s uploaded by users.\n",
    "> adds overhead for managing, scaling, and protecting the server.\n",
    "\n",
    "24. What are three examples of problems that could occur when rolling out a bear warning system in practice?\n",
    "\n",
    "> The textbook provides examples caused by out-of-domain data:\n",
    "* detect bears correctly but take too long to be useful in practice.\n",
    "* detect bears incorrectly and trigger false alarms.\n",
    "* training and production data don’t match, so the system won't work.\n",
    "\n",
    "25. What is \"out-of-domain data\"?\n",
    "\n",
    "> Data that is significantly different in some respect from the training data.\n",
    "\n",
    "26. What is \"domain shift\"?\n",
    "\n",
    "> When **production** data changes over time such that production no longer reflects data used for **training**\n",
    "\n",
    "27. What are the three steps in the deployment process?\n",
    "\n",
    "> Manual process: Run model in parallel + human checks all predictions\n",
    "\n",
    "> Limited scope deployment: Careful human supervision + time or geography limited\n",
    "\n",
    "> Gradual expansion: Good reporting systems required + consider what could go wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider how the Drivetrain Approach maps to a project or problem you're interested in.\n",
    "1. When might it be best to avoid certain types of data augmentation?\n",
    "1. For a project you're interested in applying deep learning to, consider the thought experiment \"What would happen if it went really, really well?\"\n",
    "1. Start a blog, and write your first blog post. For instance, write about what you think deep learning might be useful for in a domain you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
