{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter notes\n",
    "\n",
    "Centrality of metrics in driving a financially important system.\n",
    "\n",
    "Meetup’s algorithm -> a company not just unthinkingly optimize a metric but considering its impact.\n",
    "\n",
    "Quote from Evan Estola:\n",
    "> “You need to decide which feature not to use in your algorithm... the most optimal algorithm is perhaps not the best one to launch into production.\"\n",
    "\n",
    "Anticipate feedback loops, and “take positive action to break it when you see the first signs of it in your own projects.”\n",
    "\n",
    "Ethics is complicated and context-dependent. It involves the perspectives of many stakeholders. Ethics is a muscle that you have to develop and practice. \n",
    "\n",
    "One very natural reaction to considering these issues is: \"So what? What's that got to do with me? I'm a data scientist, not a politician. I'm not one of the senior \n",
    "\n",
    "executives at my company who make the decisions about what we do. I'm just trying to build the most predictive model I can.\"\n",
    "\n",
    "No one is better placed to inform everyone involved in this chain about the capabilities, constraints, and details of your work than you are. – call to arms. Encourage ethical behaviour at the time.\n",
    "\n",
    "Now, as you are collecting your data and developing your model, you are making lots of decisions. What level of aggregation will you store your data at? What loss function should you use? What validation and training sets should you use? Should you focus on simplicity of implementation, speed of inference, or accuracy of the model? How will your model handle out-of-domain data items? Can it be fine-tuned, or must it be retrained from scratch over time?\n",
    "\n",
    "Data scientists need to be part of a cross-disciplinary team. And researchers need to work closely with the kinds of people who will end up using their research.\n",
    "It's the kind of work that tends to be highly appreciated by senior executives, even if it is sometimes considered rather uncomfortable by middle management.\n",
    "\n",
    "*The statement above was an interesting read in the context of the firing of Timnit Gebru by Google (on the same day in 2020).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture notes\n",
    "\n",
    "### Feedback loops\n",
    "\n",
    "Can occur when your model controls the next round of data you get.\n",
    "\n",
    "Key difference between academic science and/or social science vs. community practice -> an awareness that you are an actor within the system. Scientific perspective is that you are observing data, while in machine learning the model you build and the product it sits within is likely interacting with the real world. And therefore the model affects what the data looks like. That is a key point for my own PhD research.\n",
    "\n",
    "### Getting specific about bias\n",
    "\n",
    "Centre for Applied Ethics – focused on immediate harms, not a long time in the future (i.e. AI ethics)\n",
    "\n",
    "Harini Suresh and John V Guttag ‘A Framework for Understanding Unintended Consequences of Machine Learning’, or ‘The Problem with “Biased Data”’ blog post.\n",
    "\n",
    "Clean, simplified, and logical abstractions that computer scientists deal with.\n",
    "\n",
    "Kristian Lum, Elizabeth Bender and Terrence Wilkerson -> see FAccT paper ‘Translating to Computer Science’. In the paper Does Machine Learning Automate Moral Hazard and Error why is sinusitis found to be predictive of a stroke? -> people that utilise health care a lot go in when they have sinusitis, and stroke. We are not measuring stroke, we are measuring health care use.\n",
    "\n",
    "Mitigate against measurement bias -> subtle issue, could it be improved through system dnamics. A single black member of a jury -> even a tiny bit of diversity improves bias.\n",
    "\n",
    "### Difference between humans and machines\n",
    "\n",
    "How are machines and people different, in terms of their use for making decisions?\n",
    "* ML can create feedback loops\n",
    "* ML can amplify bias.\n",
    "* Algorithms used very differently to humans in practice.\n",
    "* People assume algorithms are objective or error-free\n",
    "* Often used without appeals process\n",
    "* Often used at scale\n",
    "* Algorithmic systems are cheap\n",
    "\n",
    "See Cathy O’Neils comments in WMD book -> privileged are processed by people, poor are processed by algorithms.\n",
    "* Technology is power -> with that comes responsibility.\n",
    "Domain experts important to find when developing algorithms, for feedback. But how should they be engaged?\n",
    "\n",
    "Questions to ask:\n",
    "* Should we do this?\n",
    "* What bias is in the data? All data contains bias.\n",
    "* Can the cost and data be audited?\n",
    "* Really important to investigate error rates for different sub-groups.\n",
    "* What is the accuracy of a simple rule-based alternative (a baseline)\n",
    "* What processes are in place to handle appeals or mistakes?\n",
    "* How diverse is the team that built it?\n",
    "\n",
    "### Ethical Foundations\n",
    "\n",
    "Platform neutrality -> no given design decisions.\n",
    "Markkula Centre – see consequentialist questions:\n",
    "* who will be directly and indirectly affected by the relevant technology\n",
    "* [See others at 1:35:00 in Lesson 5 of fast.ai course]\n",
    "\n",
    "Expanding the ethical circle:\n",
    "* See [Markkula Centre document](https://www.scu.edu/ethics-in-technology-practice/ethical-toolkit/)\n",
    "* [Diverse Voices Methodology](https://techpolicylab.uw.edu/project/diverse-voices/)\n",
    "\n",
    "### Role of policy\n",
    "\n",
    "See datasheets for datasets document -> stories of regulation of three industries (car safety, electronics industry, other). See 99% invisible podcast for car safety podcast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Does ethics provide a list of \"right answers\"?\n",
    "1. How can working with people of different backgrounds help when considering ethical questions?\n",
    "1. What was the role of IBM in Nazi Germany? Why did the company participate as it did? Why did the workers participate?\n",
    "1. What was the role of the first person jailed in the Volkswagen diesel scandal?\n",
    "1. What was the problem with a database of suspected gang members maintained by California law enforcement officials?\n",
    "1. Why did YouTube's recommendation algorithm recommend videos of partially clothed children to pedophiles, even though no employee at Google had programmed this feature?\n",
    "1. What are the problems with the centrality of metrics?\n",
    "1. Why did Meetup.com not include gender in its recommendation system for tech meetups?\n",
    "1. What are the six types of bias in machine learning, according to Suresh and Guttag?\n",
    "1. Give two examples of historical race bias in the US.\n",
    "1. Where are most images in ImageNet from?\n",
    "1. In the paper [\"Does Machine Learning Automate Moral Hazard and Error\"](https://scholar.harvard.edu/files/sendhil/files/aer.p20171084.pdf) why is sinusitis found to be predictive of a stroke?\n",
    "1. What is representation bias?\n",
    "1. How are machines and people different, in terms of their use for making decisions?\n",
    "1. Is disinformation the same as \"fake news\"?\n",
    "1. Why is disinformation through auto-generated text a particularly significant issue?\n",
    "1. What are the five ethical lenses described by the Markkula Center?\n",
    "1. Where is policy an appropriate tool for addressing data ethics issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the article \"What Happens When an Algorithm Cuts Your Healthcare\". How could problems like this be avoided in the future?\n",
    "1. Research to find out more about YouTube's recommendation system and its societal impacts. Do you think recommendation systems must always have feedback loops with negative results? What approaches could Google take to avoid them? What about the government?\n",
    "1. Read the paper [\"Discrimination in Online Ad Delivery\"](https://arxiv.org/abs/1301.6822). Do you think Google should be considered responsible for what happened to Dr. Sweeney? What would be an appropriate response?\n",
    "1. How can a cross-disciplinary team help avoid negative consequences?\n",
    "1. Read the paper \"Does Machine Learning Automate Moral Hazard and Error\". What actions do you think should be taken to deal with the issues identified in this paper?\n",
    "1. Read the article \"How Will We Prevent AI-Based Forgery?\" Do you think Etzioni's proposed approach could work? Why?\n",
    "1. Complete the section \"Analyze a Project You Are Working On\" in this chapter.\n",
    "1. Consider whether your team could be more diverse. If so, what approaches might help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning in Practice: That's a Wrap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've made it to the end of the first section of the book. In this section we've tried to show you what deep learning can do, and how you can use it to create real applications and products. At this point, you will get a lot more out of the book if you spend some time trying out what you've learned. Perhaps you have already been doing this as you go along—in which case, great! If not, that's no problem either... Now is a great time to start experimenting yourself.\n",
    "\n",
    "If you haven't been to the [book's website](https://book.fast.ai) yet, head over there now. It's really important that you get yourself set up to run the notebooks. Becoming an effective deep learning practitioner is all about practice, so you need to be training models. So, please go get the notebooks running now if you haven't already! And also have a look on the website for any important updates or notices; deep learning changes fast, and we can't change the words that are printed in this book, so the website is where you need to look to ensure you have the most up-to-date information.\n",
    "\n",
    "Make sure that you have completed the following steps:\n",
    "\n",
    "- Connect to one of the GPU Jupyter servers recommended on the book's website.\n",
    "- Run the first notebook yourself.\n",
    "- Upload an image that you find in the first notebook; then try a few different images of different kinds to see what happens.\n",
    "- Run the second notebook, collecting your own dataset based on image search queries that you come up with.\n",
    "- Think about how you can use deep learning to help you with your own projects, including what kinds of data you could use, what kinds of problems may come up, and how you might be able to mitigate these issues in practice.\n",
    "\n",
    "In the next section of the book you will learn about how and why deep learning works, instead of just seeing how you can use it in practice. Understanding the how and why is important for both practitioners and researchers, because in this fairly new field nearly every project requires some level of customization and debugging. The better you understand the foundations of deep learning, the better your models will be. These foundations are less important for executives, product managers, and so forth (although still useful, so feel free to keep reading!), but they are critical for anybody who is actually training and deploying models themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
